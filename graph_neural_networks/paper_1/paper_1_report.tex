%! Author = ashutosh
%! Date = 5/13/22

\documentclass{article}

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[letterpaper]{geometry}
\usepackage{amsmath, amssymb, enumerate, physics}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{epstopdf}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{textcomp}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
    }

\title{\textbf{Graph Neural Networks for Natural Language Processing}}
\author{Ashutosh Tiwari (ashutiwa@iu.edu)}

\begin{document}
\maketitle

This medium page was generated by \href{https://thunderock.github.io/blogs/introduction.html}{HTML document} which was generated from a \href{https://thunderock.github.io/blog_pdfs/introduction.pdf}{LaTeX document} using \href{https://github.com/michal-h20/make4ht}{make4ht}. So to see this blog in its full glory, view the pdf document.


Graphs in general have been used in natural language processing for a long time. But in most of these cases (example ~\cite{erkan-2006-language}) whether their purpose is graph matching or clustering they suffer from two main problems. First is their low expressive power because in most of cases, these do not capture the structural information and are oblivious to the node and edge features in the graph in consideration. Second issue is that all these different kind of graphs are different and thus their representations are not comparable. Therefore it is very difficult to transfer the knowledge from one graph to another.


Very recently inspired by success of neural networks and graphs, Graph Neural Networks started to gain traction in research circles. In this article we are only focussed for their use in Natural Language Processing, but it is worth noting that they are being increasingly used in other areas as well. 

\bibliographystyle{alpha}

\bibliography{ashutiwa}

\end{document}